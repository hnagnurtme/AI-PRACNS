# Training Configuration for SAGIN RL Agent

# Agent architecture
agent:
  type: "DQN"  # Deep Q-Network
  architecture: "feedforward"

  # Network architecture
  hidden_layers:
    - 256
    - 256
    - 128

  activation: "relu"
  output_activation: "linear"
  dropout_rate: 0.1
  use_batch_norm: false

# Training hyperparameters
training:
  # Episode settings
  num_episodes: 2000
  max_steps_per_episode: 50
  max_hops: 12

  # Learning rate
  learning_rate: 0.0005
  lr_scheduler:
    enabled: true
    type: "step"
    step_size: 500
    gamma: 0.9

  # Discount factor
  gamma: 0.98

  # Exploration strategy (epsilon-greedy)
  epsilon_start: 1.0
  epsilon_end: 0.02
  epsilon_decay: 8000
  epsilon_decay_type: "exponential"  # linear or exponential

  # Experience replay
  replay_buffer_size: 100000
  min_replay_size: 1000
  batch_size: 128
  prioritized_replay: false
  priority_alpha: 0.6
  priority_beta: 0.4

  # Target network
  target_update_frequency: 20  # episodes
  soft_update: false
  tau: 0.001  # for soft update

  # Gradient clipping
  gradient_clip: 1.0

  # Optimization
  optimizer: "adam"
  weight_decay: 0.0001

# Checkpointing
checkpointing:
  enabled: true
  save_frequency: 100  # episodes
  checkpoint_dir: "checkpoints/models"
  keep_last_n: 5
  save_best: true
  metric: "avg_reward"  # avg_reward, delivery_rate, avg_latency

# Logging
logging:
  enabled: true
  log_frequency: 10  # episodes
  tensorboard: true
  tensorboard_dir: "logs/tensorboard"
  csv_log: true
  csv_log_path: "logs/training_log.csv"
  wandb: false
  wandb_project: "sagin-rl-routing"

# Evaluation during training
evaluation:
  enabled: true
  eval_frequency: 100  # episodes
  num_eval_episodes: 50
  deterministic: true
  save_eval_trajectories: false

# Early stopping
early_stopping:
  enabled: false
  patience: 200  # episodes
  min_delta: 0.01
  metric: "avg_reward"

# Multi-agent settings (if applicable)
multi_agent:
  enabled: false
  num_agents: 1
  shared_replay_buffer: true
  centralized_training: false

# Curriculum learning
curriculum:
  enabled: false
  stages:
    - name: "easy"
      episodes: 500
      dynamics:
        weather:
          enabled: false
        failures:
          enabled: false

    - name: "medium"
      episodes: 1000
      dynamics:
        weather:
          enabled: true
        failures:
          node_failure_prob: 0.0005

    - name: "hard"
      episodes: 1500
      dynamics:
        weather:
          enabled: true
        failures:
          node_failure_prob: 0.001

# Hardware/Performance settings
hardware:
  device: "auto"  # auto, cpu, cuda, mps
  num_workers: 4
  pin_memory: true
  mixed_precision: false
