# python/service/tcp_inference_service.py

import socket
import json
import logging
import torch
import numpy as np
from typing import Dict, Any, List, Tuple

# Imports t·ª´ c√°c module RL ƒë√£ x√¢y d·ª±ng
from ..utils.db_connector import MongoConnector
from ..utils.state_builder import StateBuilder, MAX_NEIGHBORS # (NOTE) Import MAX_NEIGHBORS (10)
# (NOTE) Import ki·∫øn tr√∫c 94/10
from ..rl_agent.dqn_model import DQN, INPUT_SIZE, OUTPUT_SIZE 
# (NOTE) X√≥a import NodeService, kh√¥ng c·∫ßn thi·∫øt

# ===================== C·∫§U H√åNH D·ªäCH V·ª§ =====================
HOST = '0.0.0.0'
PORT = 65000
MODEL_PATH = "models/checkpoints/dqn_checkpoint_fullpath_latest.pth"

# Logger
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ===================== 1. LOAD COMPONENTS =====================
def load_components() -> Tuple[DQN, StateBuilder]:
    """T·∫£i m√¥ h√¨nh DQN, k·∫øt n·ªëi MongoDB, kh·ªüi t·∫°o StateBuilder."""
    logger.info("1. ƒêang t·∫£i m√¥ h√¨nh DQN...")

    model = DQN(INPUT_SIZE, OUTPUT_SIZE)

    try:
        # (PYTORCH ‚â• 2.6) Th√™m weights_only=False n·∫øu c√≥
        try:
            checkpoint = torch.load(MODEL_PATH, weights_only=False)
        except TypeError:
            checkpoint = torch.load(MODEL_PATH)

        # üß† Ki·ªÉm tra lo·∫°i checkpoint
        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            model.load_state_dict(checkpoint["model_state_dict"])
            logger.info("‚úÖ ƒê√£ load model_state_dict t·ª´ checkpoint.")
        else:
            # File ch·ªâ ch·ª©a state_dict thu·∫ßn
            model.load_state_dict(checkpoint)
            logger.info("‚úÖ ƒê√£ load state_dict tr·ª±c ti·∫øp.")

    except FileNotFoundError:
        logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i {MODEL_PATH}.")
        raise
    except RuntimeError as e:
        logger.error(f"‚ùå Ki·∫øn tr√∫c model kh√¥ng kh·ªõp: {e}")
        raise
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi load checkpoint: {e}")
        raise

    model.eval()

    logger.info("2. K·∫øt n·ªëi MongoDB...")
    mongo_conn = MongoConnector()
    state_builder = StateBuilder(mongo_conn)

    logger.info(f"‚úÖ DQN Agent (94-In, 10-Out) ƒë√£ s·∫µn s√†ng.")
    return model, state_builder


# ===================== 2. PATH PREDICTION =====================
def get_optimal_path(model: DQN, state_builder: StateBuilder, packet_data: Dict[str, Any],
                     max_hops: int = 50) -> Tuple[List[str], str]:
    """
    (T·ªêI ∆ØU) D·ª± ƒëo√°n to√†n b·ªô path d·ª±a tr√™n DQN,
    kh·ªõp policy v√† ch·ªëng l·∫∑p v√≤ng hi·ªáu qu·∫£.
    """
    start_node = packet_data.get('currentHoldingNodeId')
    if not start_node:
        return ["ERROR_START_NODE"], "ERROR:missing_start_node"

    path: List[str] = [str(start_node)]
    current_packet = packet_data.copy()
    current_packet['path'] = path
    hops = 0
    visited_nodes = set([start_node]) # (T·ªêI ∆ØU) D√πng set ƒë·ªÉ ch·ªëng l·∫∑p to√†n path

    while hops < max_hops:
        current_node_id = current_packet.get('currentHoldingNodeId')
        dest_node_id = current_packet.get('stationDest')

        if current_node_id == dest_node_id:
            return path, "SUCCESS"

        if current_packet.get('dropped', False) or current_packet.get('ttl', 0) <= 0:
            return path, "DROP_TTL"

        try:
            # 1. L·∫•y tr·∫°ng th√°i vector S (94 chi·ªÅu)
            state_vector = state_builder.get_state_vector(current_packet)
            state_tensor = torch.from_numpy(state_vector).float().unsqueeze(0)

            # 2. L·∫•y neighbor th·ª±c t·∫ø t·ª´ DB
            # (NOTE) ƒê√¢y l√† danh s√°ch neighbor m√† StateBuilder ƒë√£ d√πng
            current_node = state_builder.db.get_node(str(current_node_id), projection={'neighbors': 1})
            neighbor_ids_full = current_node.get('neighbors', []) if current_node else []
            
            # (NOTE) Ch·ªâ l·∫•y t·ªëi ƒëa 10 neighbor ƒë·∫ßu ti√™n ƒë·ªÉ kh·ªõp policy
            neighbor_ids = neighbor_ids_full[:MAX_NEIGHBORS]
            neighbor_count = len(neighbor_ids)

            if not neighbor_ids:
                return path, "NO_NEIGHBORS"

            # (T·ªêI ∆ØU) X√≥a b·ªè heuristic top-k
            # Agent ph·∫£i quy·∫øt ƒë·ªãnh d·ª±a tr√™n state vector ƒë·∫ßy ƒë·ªß.

            # 3. DQN inference
            with torch.no_grad():
                q_values_tensor = model(state_tensor) # Tr·∫£ v·ªÅ 10 Q-values
            q_values = q_values_tensor.cpu().numpy().flatten()

            # (T·ªêI ∆ØU) Masking Q-values
            # Ch·ªâ quan t√¢m ƒë·∫øn Q-values c·ªßa c√°c neighbor th·ª±c s·ª± t·ªìn t·∫°i
            # G√°n Q-value c·ªßa c√°c h√†nh ƒë·ªông kh√¥ng h·ª£p l·ªá (vd: h√†nh ƒë·ªông 8, 9
            # khi ch·ªâ c√≥ 7 neighbor) l√† -v√¥ c√πng
            valid_q_values = np.full(OUTPUT_SIZE, -np.inf, dtype=np.float32)
            valid_q_values[:neighbor_count] = q_values[:neighbor_count]

            # 4. (T·ªêI ∆ØU) Loop prevention
            last_node_id = path[-2] if len(path) >= 2 else None
            
            for _ in range(neighbor_count):
                # Ch·ªçn h√†nh ƒë·ªông t·ªët nh·∫•t t·ª´ Q-values H·ª¢P L·ªÜ
                action_index = int(np.argmax(valid_q_values))
                next_hop = neighbor_ids[action_index]
                
                # Ki·ªÉm tra l·∫∑p v√≤ng
                if next_hop != last_node_id and next_hop not in visited_nodes:
                    break # H√†nh ƒë·ªông t·ªët, kh√¥ng l·∫∑p
                
                # B·ªã l·∫∑p: Lo·∫°i b·ªè h√†nh ƒë·ªông n√†y v√† ch·ªçn l·∫°i
                valid_q_values[action_index] = -np.inf # Ph·∫°t
            else:
                # (T·ªêI ∆ØU) N·∫øu t·∫•t c·∫£ 10 h√†nh ƒë·ªông ƒë·ªÅu b·ªã l·∫∑p
                return path, "LOOP_STUCK"

            # 5. C·∫≠p nh·∫≠t path v√† packet state
            path.append(next_hop)
            visited_nodes.add(next_hop) # Th√™m v√†o danh s√°ch ƒë√£ thƒÉm
            current_packet['currentHoldingNodeId'] = next_hop
            current_packet['path'] = path
            current_packet['ttl'] = max(current_packet.get('ttl', 10) - 1, 0)
            hops += 1

        except Exception as e:
            logger.error(f"Error in path prediction: {e}", exc_info=True)
            return path, f"ERROR:{e}"

    return path, "MAX_HOPS_EXCEEDED"

# ===================== 3. TCP SERVER =====================
def start_tcp_server():
    model, state_builder = load_components()
    
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind((HOST, PORT))
        s.listen()
        logger.info(f"üöÄ RL Router (94/10) listening on {HOST}:{PORT} (TCP)")

        while True:
            conn, addr = s.accept()
            # (T·ªêI ∆ØU) S·ª≠ d·ª•ng makefile ƒë·ªÉ x·ª≠ l√Ω stream (nhi·ªÅu req/k·∫øt n·ªëi)
            with conn, conn.makefile('rb') as rfile, conn.makefile('wb') as wfile:
                logger.info(f"Connection established with {addr}")
                try:
                    # V√≤ng l·∫∑p x·ª≠ l√Ω nhi·ªÅu JSON tr√™n 1 k·∫øt n·ªëi
                    while True:
                        line = rfile.readline() # ƒê·ªçc ƒë·∫øn khi g·∫∑p '\n'
                        if not line:
                            break # Client ƒë√≥ng k·∫øt n·ªëi

                        request_json = json.loads(line.strip().decode('utf-8'))
                        
                        # L·∫•y path t·ªëi ∆∞u
                        path_list, status = get_optimal_path(model, state_builder, request_json, max_hops=20)
                        
                        # Tr·∫£ v·ªÅ hop ti·∫øp theo
                        next_hop_id = path_list[1] if len(path_list) > 1 else path_list[0]

                        response_obj = {
                            "nextHopNodeId": next_hop_id,
                            "path": path_list,
                            "algorithm": "RL-DQN-10N", # (NOTE) T√™n m·ªõi
                            "status": status
                        }

                        response_bytes = (json.dumps(response_obj) + "\n").encode('utf-8')
                        wfile.write(response_bytes)
                        wfile.flush() # ƒê·∫©y d·ªØ li·ªáu ƒëi ngay

                except json.JSONDecodeError:
                    error_msg = json.dumps({"status": "ERROR", "message": "Invalid JSON format."}) + "\n"
                    wfile.write(error_msg.encode('utf-8'))
                    wfile.flush()
                except Exception as e:
                    logger.error(f"Error processing request from {addr}: {e}", exc_info=True)
                
                logger.info(f"Connection closed with {addr}")

if __name__ == "__main__":
    start_tcp_server()